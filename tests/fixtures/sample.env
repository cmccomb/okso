# Sample environment configuration for do assistant
# DO_MODEL_PATH (string): path to llama.cpp model to load.
DO_MODEL_PATH=./models/demo.gguf
# DO_SUPERVISED (bool): true to require confirmation before running tools.
DO_SUPERVISED=false
# DO_VERBOSITY (int): 0=quiet, 1=info, 2=debug.
DO_VERBOSITY=2
# LLAMA_BIN (string): llama.cpp binary to use for scoring; can be a stub during testing.
LLAMA_BIN=./bin/llama-mock
